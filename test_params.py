#!/usr/bin/env python3
"""
Neuro-LLM-Serverã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿè£…ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import requests
import json
import base64
from PIL import Image
from io import BytesIO

# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ç”»åƒã‚’ç”Ÿæˆ
def create_test_image():
    """ãƒ†ã‚¹ãƒˆç”¨ã®å°ã•ãªç”»åƒã‚’ç”Ÿæˆ"""
    img = Image.new('RGB', (100, 100), color=(255, 0, 0))
    buffer = BytesIO()
    img.save(buffer, format='JPEG')
    img_bytes = buffer.getvalue()
    img_base64 = base64.b64encode(img_bytes).decode('utf-8')
    return f"data:image/jpeg;base64,{img_base64}"

def test_streaming():
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("ãƒ†ã‚¹ãƒˆ1: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰")
    print("=" * 60)

    url = "http://127.0.0.1:8000/v1/chat/completions"
    payload = {
        "messages": [{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "ã“ã®ç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": create_test_image()
                    }
                }
            ]
        }],
        "stream": True,
        "temperature": 0.7,
        "max_tokens": 50
    }

    try:
        response = requests.post(url, json=payload, stream=True, timeout=30)
        if response.status_code == 200:
            print("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡é–‹å§‹")
            chunk_count = 0
            for line in response.iter_lines():
                if line:
                    line_str = line.decode('utf-8')
                    if line_str.startswith('data: '):
                        data_str = line_str[6:]  # 'data: 'ã‚’é™¤å»
                        if data_str.strip() == '[DONE]':
                            break
                        try:
                            chunk = json.loads(data_str)
                            if 'choices' in chunk and len(chunk['choices']) > 0:
                                delta = chunk['choices'][0].get('delta', {})
                                content = delta.get('content', '')
                                if content:
                                    print(content, end='', flush=True)
                                    chunk_count += 1
                        except json.JSONDecodeError:
                            pass
            print(f"\nâœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆ{chunk_count}ãƒãƒ£ãƒ³ã‚¯å—ä¿¡ï¼‰")
        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(response.text)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def test_non_streaming():
    """éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆ2: éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰")
    print("=" * 60)

    url = "http://127.0.0.1:8000/v1/chat/completions"
    payload = {
        "messages": [{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "ã“ã®ç”»åƒã¯ä½•è‰²ã§ã™ã‹ï¼Ÿ"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": create_test_image()
                    }
                }
            ]
        }],
        "stream": False,
        "temperature": 0.5,
        "max_tokens": 30,
        "top_p": 0.9,
        "stop": ["ã€‚", "\n"]
    }

    try:
        response = requests.post(url, json=payload, timeout=30)
        if response.status_code == 200:
            result = response.json()
            print("âœ… éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡")
            print(f"å¿œç­”: {result.get('choices', [{}])[0].get('message', {}).get('content', '')}")
            print(f"ãƒ¢ãƒ‡ãƒ«: {result.get('model', 'N/A')}")
        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(response.text)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def test_parameters():
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ­£ã—ãå—ã‘å–ã‚‰ã‚Œã¦ã„ã‚‹ã‹ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆ3: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å—ã‘å–ã‚Šç¢ºèªï¼ˆmax_tokensåˆ¶é™ï¼‰")
    print("=" * 60)

    url = "http://127.0.0.1:8000/v1/chat/completions"
    payload = {
        "messages": [{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "1ã‹ã‚‰10ã¾ã§æ•°ãˆã¦ãã ã•ã„ã€‚"
                }
            ]
        }],
        "stream": True,
        "max_tokens": 20,  # çŸ­ãåˆ¶é™
        "temperature": 0.7
    }

    try:
        response = requests.post(url, json=payload, stream=True, timeout=30)
        if response.status_code == 200:
            print("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡é–‹å§‹ï¼ˆmax_tokens=20ã§åˆ¶é™ï¼‰")
            total_chars = 0
            for line in response.iter_lines():
                if line:
                    line_str = line.decode('utf-8')
                    if line_str.startswith('data: '):
                        data_str = line_str[6:]
                        if data_str.strip() == '[DONE]':
                            break
                        try:
                            chunk = json.loads(data_str)
                            if 'choices' in chunk and len(chunk['choices']) > 0:
                                delta = chunk['choices'][0].get('delta', {})
                                content = delta.get('content', '')
                                if content:
                                    print(content, end='', flush=True)
                                    total_chars += len(content)
                        except json.JSONDecodeError:
                            pass
            print(f"\nâœ… max_tokensåˆ¶é™ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆåˆè¨ˆ{total_chars}æ–‡å­—ï¼‰")
        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(response.text)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    print("ğŸ§ª Neuro-LLM-Server ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿè£…ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    print("ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„: http://127.0.0.1:8000")
    print("=" * 60)

    # ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ç¢ºèª
    try:
        response = requests.get("http://127.0.0.1:8000/docs", timeout=5)
        if response.status_code == 200:
            print("âœ… Neuro-LLM-Serverã«æ¥ç¶šã§ãã¾ã—ãŸ\n")
        else:
            print("âš ï¸  Neuro-LLM-Serverã«æ¥ç¶šã§ãã¾ã›ã‚“ï¼ˆèµ·å‹•ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰\n")
    except Exception as e:
        print(f"âš ï¸  Neuro-LLM-Serverã«æ¥ç¶šã§ãã¾ã›ã‚“: {e}\n")
        print("ğŸ’¡ ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„:")
        print("   cd tools/Neuro-LLM-Server")
        print("   source venv/bin/activate")
        print("   uvicorn main:app --host 127.0.0.1 --port 8000")
        exit(1)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_streaming()
    test_non_streaming()
    test_parameters()

    print("\n" + "=" * 60)
    print("âœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 60)
